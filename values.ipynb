{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27d393c9",
   "metadata": {},
   "source": [
    "# SONAR MODEL EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5dd3daf9-e347-466f-812a-d940d26e2d6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/nihesh/Nihesh/sonar/.venv/bin/pip3\n",
      "/Users/nihesh/Nihesh/sonar/.venv/bin/python3\n"
     ]
    }
   ],
   "source": [
    "!which pip3\n",
    "!which python3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31c67047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in ./.venv/lib/python3.12/site-packages (25.2)\n",
      "Collecting setuptools\n",
      "  Using cached setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting wheel\n",
      "  Using cached wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "Using cached setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n",
      "Using cached wheel-0.45.1-py3-none-any.whl (72 kB)\n",
      "Installing collected packages: wheel, setuptools\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [setuptools]2\u001b[0m [setuptools]\n",
      "\u001b[1A\u001b[2KSuccessfully installed setuptools-80.9.0 wheel-0.45.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting torch\n",
      "  Downloading torch-2.8.0-cp312-none-macosx_11_0_arm64.whl.metadata (30 kB)\n",
      "Collecting torchaudio\n",
      "  Downloading torchaudio-2.8.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (7.2 kB)\n",
      "Collecting filelock (from torch)\n",
      "  Using cached filelock-3.19.1-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting typing-extensions>=4.10.0 (from torch)\n",
      "  Using cached typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.12/site-packages (from torch) (80.9.0)\n",
      "Collecting sympy>=1.13.3 (from torch)\n",
      "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch)\n",
      "  Using cached networkx-3.5-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting jinja2 (from torch)\n",
      "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting fsspec (from torch)\n",
      "  Using cached fsspec-2025.7.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch)\n",
      "  Using cached MarkupSafe-3.0.2-cp312-cp312-macosx_11_0_arm64.whl.metadata (4.0 kB)\n",
      "Downloading torch-2.8.0-cp312-none-macosx_11_0_arm64.whl (73.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m  \u001b[33m0:00:25\u001b[0mm0:00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading torchaudio-2.8.0-cp312-cp312-macosx_11_0_arm64.whl (1.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Using cached typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
      "Using cached filelock-3.19.1-py3-none-any.whl (15 kB)\n",
      "Using cached fsspec-2025.7.0-py3-none-any.whl (199 kB)\n",
      "Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Using cached MarkupSafe-3.0.2-cp312-cp312-macosx_11_0_arm64.whl (12 kB)\n",
      "Using cached networkx-3.5-py3-none-any.whl (2.0 MB)\n",
      "Installing collected packages: mpmath, typing-extensions, sympy, networkx, MarkupSafe, fsspec, filelock, jinja2, torch, torchaudio\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10/10\u001b[0m [torchaudio]0\u001b[0m [torchaudio]\n",
      "\u001b[1A\u001b[2KSuccessfully installed MarkupSafe-3.0.2 filelock-3.19.1 fsspec-2025.7.0 jinja2-3.1.6 mpmath-1.3.0 networkx-3.5 sympy-1.14.0 torch-2.8.0 torchaudio-2.8.0 typing-extensions-4.15.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting numpy\n",
      "  Using cached numpy-2.3.2-cp312-cp312-macosx_14_0_arm64.whl.metadata (62 kB)\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.10.6-cp312-cp312-macosx_11_0_arm64.whl.metadata (11 kB)\n",
      "Collecting pydub\n",
      "  Using cached pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting sacrebleu\n",
      "  Using cached sacrebleu-2.5.1-py3-none-any.whl.metadata (51 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Using cached contourpy-1.3.3-cp312-cp312-macosx_11_0_arm64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.59.2-cp312-cp312-macosx_10_13_universal2.whl.metadata (109 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Downloading kiwisolver-1.4.9-cp312-cp312-macosx_11_0_arm64.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.12/site-packages (from matplotlib) (25.0)\n",
      "Collecting pillow>=8 (from matplotlib)\n",
      "  Using cached pillow-11.3.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (9.0 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
      "  Using cached pyparsing-3.2.3-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./.venv/lib/python3.12/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Collecting portalocker (from sacrebleu)\n",
      "  Using cached portalocker-3.2.0-py3-none-any.whl.metadata (8.7 kB)\n",
      "Collecting regex (from sacrebleu)\n",
      "  Downloading regex-2025.8.29-cp312-cp312-macosx_11_0_arm64.whl.metadata (40 kB)\n",
      "Collecting tabulate>=0.8.9 (from sacrebleu)\n",
      "  Using cached tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
      "Collecting colorama (from sacrebleu)\n",
      "  Using cached colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
      "Collecting lxml (from sacrebleu)\n",
      "  Downloading lxml-6.0.1-cp312-cp312-macosx_10_13_universal2.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Downloading numpy-2.3.2-cp312-cp312-macosx_14_0_arm64.whl (5.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading matplotlib-3.10.6-cp312-cp312-macosx_11_0_arm64.whl (8.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.1/8.1 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Using cached sacrebleu-2.5.1-py3-none-any.whl (104 kB)\n",
      "Using cached contourpy-1.3.3-cp312-cp312-macosx_11_0_arm64.whl (273 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.59.2-cp312-cp312-macosx_10_13_universal2.whl (2.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading kiwisolver-1.4.9-cp312-cp312-macosx_11_0_arm64.whl (64 kB)\n",
      "Using cached pillow-11.3.0-cp312-cp312-macosx_11_0_arm64.whl (4.7 MB)\n",
      "Using cached pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
      "Using cached tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Using cached colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "Downloading lxml-6.0.1-cp312-cp312-macosx_10_13_universal2.whl (8.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m eta \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hUsing cached portalocker-3.2.0-py3-none-any.whl (22 kB)\n",
      "Downloading regex-2025.8.29-cp312-cp312-macosx_11_0_arm64.whl (286 kB)\n",
      "Installing collected packages: pydub, tabulate, regex, pyparsing, portalocker, pillow, numpy, lxml, kiwisolver, fonttools, cycler, colorama, sacrebleu, contourpy, matplotlib\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15/15\u001b[0m [matplotlib]5\u001b[0m [matplotlib]\n",
      "\u001b[1A\u001b[2KSuccessfully installed colorama-0.4.6 contourpy-1.3.3 cycler-0.12.1 fonttools-4.59.2 kiwisolver-1.4.9 lxml-6.0.1 matplotlib-3.10.6 numpy-2.3.2 pillow-11.3.0 portalocker-3.2.0 pydub-0.25.1 pyparsing-3.2.3 regex-2025.8.29 sacrebleu-2.5.1 tabulate-0.9.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.2.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (10 kB)\n",
      "Downloading sentencepiece-0.2.1-cp312-cp312-macosx_11_0_arm64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: sentencepiece\n",
      "Successfully installed sentencepiece-0.2.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install dependencies step by step to avoid conflicts\n",
    "%pip install --upgrade pip setuptools wheel\n",
    "%pip install torch torchaudio\n",
    "%pip install numpy matplotlib pydub sacrebleu\n",
    "%pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b46df55d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch==2.6.0\n",
      "  Using cached torch-2.6.0-cp312-none-macosx_11_0_arm64.whl.metadata (28 kB)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.12/site-packages (from torch==2.6.0) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in ./.venv/lib/python3.12/site-packages (from torch==2.6.0) (4.15.0)\n",
      "Requirement already satisfied: networkx in ./.venv/lib/python3.12/site-packages (from torch==2.6.0) (3.5)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.12/site-packages (from torch==2.6.0) (3.1.6)\n",
      "Requirement already satisfied: fsspec in ./.venv/lib/python3.12/site-packages (from torch==2.6.0) (2025.7.0)\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.12/site-packages (from torch==2.6.0) (80.9.0)\n",
      "Collecting sympy==1.13.1 (from torch==2.6.0)\n",
      "  Using cached sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.12/site-packages (from sympy==1.13.1->torch==2.6.0) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.12/site-packages (from jinja2->torch==2.6.0) (3.0.2)\n",
      "Using cached torch-2.6.0-cp312-none-macosx_11_0_arm64.whl (66.5 MB)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.12/site-packages (from torch==2.6.0) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in ./.venv/lib/python3.12/site-packages (from torch==2.6.0) (4.15.0)\n",
      "Requirement already satisfied: networkx in ./.venv/lib/python3.12/site-packages (from torch==2.6.0) (3.5)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.12/site-packages (from torch==2.6.0) (3.1.6)\n",
      "Requirement already satisfied: fsspec in ./.venv/lib/python3.12/site-packages (from torch==2.6.0) (2025.7.0)\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.12/site-packages (from torch==2.6.0) (80.9.0)\n",
      "Collecting sympy==1.13.1 (from torch==2.6.0)\n",
      "  Using cached sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.12/site-packages (from sympy==1.13.1->torch==2.6.0) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.12/site-packages (from jinja2->torch==2.6.0) (3.0.2)\n",
      "Using cached torch-2.6.0-cp312-none-macosx_11_0_arm64.whl (66.5 MB)\n",
      "Using cached sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "Using cached sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "Installing collected packages: sympy, torch\n",
      "\u001b[2K  Attempting uninstall: sympy\n",
      "\u001b[2K    Found existing installation: sympy 1.14.0\n",
      "Installing collected packages: sympy, torch\n",
      "\u001b[2K  Attempting uninstall: sympy\n",
      "\u001b[2K    Found existing installation: sympy 1.14.0\n",
      "\u001b[2K    Uninstalling sympy-1.14.0:\n",
      "\u001b[2K    Uninstalling sympy-1.14.0:\n",
      "\u001b[2K      Successfully uninstalled sympy-1.14.0\n",
      "\u001b[2K      Successfully uninstalled sympy-1.14.0━━━━━\u001b[0m \u001b[32m0/2\u001b[0m [sympy]\n",
      "\u001b[2K  Attempting uninstall: torch━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0/2\u001b[0m [sympy]\n",
      "\u001b[2K  Attempting uninstall: torch━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0/2\u001b[0m [sympy]\n",
      "\u001b[2K    Found existing installation: torch 2.8.0\u001b[0m \u001b[32m0/2\u001b[0m [sympy]\n",
      "\u001b[2K    Found existing installation: torch 2.8.090m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/2\u001b[0m [torch]\n",
      "\u001b[2K    Uninstalling torch-2.8.0:[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/2\u001b[0m [torch]\n",
      "\u001b[2K    Uninstalling torch-2.8.0:[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/2\u001b[0m [torch]\n",
      "\u001b[2K      Successfully uninstalled torch-2.8.0m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/2\u001b[0m [torch]\n",
      "\u001b[2K      Successfully uninstalled torch-2.8.0m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/2\u001b[0m [torch]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [torch]32m1/2\u001b[0m [torch]\n",
      "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchaudio 2.8.0 requires torch==2.8.0, but you have torch 2.6.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed sympy-1.13.1 torch-2.6.0\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [torch]\n",
      "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchaudio 2.8.0 requires torch==2.8.0, but you have torch 2.6.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed sympy-1.13.1 torch-2.6.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%pip install torch==2.6.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9353b51a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fairseq2n\n",
      "  Using cached fairseq2n-0.4.6-cp312-cp312-macosx_14_0_arm64.whl.metadata (1.2 kB)\n",
      "Collecting torch==2.6.0 (from fairseq2n)\n",
      "  Using cached torch-2.6.0-cp312-none-macosx_11_0_arm64.whl.metadata (28 kB)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.12/site-packages (from torch==2.6.0->fairseq2n) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in ./.venv/lib/python3.12/site-packages (from torch==2.6.0->fairseq2n) (4.15.0)\n",
      "Requirement already satisfied: networkx in ./.venv/lib/python3.12/site-packages (from torch==2.6.0->fairseq2n) (3.5)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.12/site-packages (from torch==2.6.0->fairseq2n) (3.1.6)\n",
      "Requirement already satisfied: fsspec in ./.venv/lib/python3.12/site-packages (from torch==2.6.0->fairseq2n) (2025.7.0)\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.12/site-packages (from torch==2.6.0->fairseq2n) (80.9.0)\n",
      "Collecting sympy==1.13.1 (from torch==2.6.0->fairseq2n)\n",
      "  Using cached sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.12/site-packages (from sympy==1.13.1->torch==2.6.0->fairseq2n) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.12/site-packages (from jinja2->torch==2.6.0->fairseq2n) (3.0.2)\n",
      "Using cached fairseq2n-0.4.6-cp312-cp312-macosx_14_0_arm64.whl (2.6 MB)\n",
      "Using cached torch-2.6.0-cp312-none-macosx_11_0_arm64.whl (66.5 MB)\n",
      "Using cached sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "Installing collected packages: sympy, torch, fairseq2n\n",
      "\u001b[2K  Attempting uninstall: sympy\n",
      "\u001b[2K    Found existing installation: sympy 1.14.0\n",
      "\u001b[2K    Uninstalling sympy-1.14.0:\n",
      "\u001b[2K      Successfully uninstalled sympy-1.14.0\n",
      "\u001b[2K  Attempting uninstall: torch━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0/3\u001b[0m [sympy]\n",
      "\u001b[2K    Found existing installation: torch 2.8.0\u001b[0m \u001b[32m0/3\u001b[0m [sympy]\n",
      "\u001b[2K    Uninstalling torch-2.8.0:m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/3\u001b[0m [torch]\n",
      "\u001b[2K      Successfully uninstalled torch-2.8.0━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/3\u001b[0m [torch]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/3\u001b[0m [fairseq2n]/3\u001b[0m [torch]\n",
      "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchaudio 2.8.0 requires torch==2.8.0, but you have torch 2.6.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed fairseq2n-0.4.6 sympy-1.13.1 torch-2.6.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting fairseq2\n",
      "  Using cached fairseq2-0.4.6-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting editdistance~=0.8 (from fairseq2)\n",
      "  Using cached editdistance-0.8.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: fairseq2n==0.4.6 in ./.venv/lib/python3.12/site-packages (from fairseq2) (0.4.6)\n",
      "Collecting importlib_metadata~=7.0 (from fairseq2)\n",
      "  Using cached importlib_metadata-7.2.1-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting importlib_resources~=6.4 (from fairseq2)\n",
      "  Using cached importlib_resources-6.5.2-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting mypy-extensions~=1.0 (from fairseq2)\n",
      "  Using cached mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting numpy~=1.23 (from fairseq2)\n",
      "  Using cached numpy-1.26.4-cp312-cp312-macosx_11_0_arm64.whl.metadata (61 kB)\n",
      "Collecting packaging~=24.1 (from fairseq2)\n",
      "  Using cached packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting psutil~=5.9 (from fairseq2)\n",
      "  Using cached psutil-5.9.8-cp38-abi3-macosx_11_0_arm64.whl.metadata (21 kB)\n",
      "Collecting pyyaml~=6.0 (from fairseq2)\n",
      "  Using cached PyYAML-6.0.2-cp312-cp312-macosx_11_0_arm64.whl.metadata (2.1 kB)\n",
      "Collecting rich~=13.7 (from fairseq2)\n",
      "  Using cached rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: sacrebleu~=2.4 in ./.venv/lib/python3.12/site-packages (from fairseq2) (2.5.1)\n",
      "Collecting tiktoken~=0.7 (from fairseq2)\n",
      "  Downloading tiktoken-0.11.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (6.7 kB)\n",
      "Collecting torcheval~=0.0.6 (from fairseq2)\n",
      "  Using cached torcheval-0.0.7-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting tqdm~=4.62 (from fairseq2)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: typing_extensions~=4.12 in ./.venv/lib/python3.12/site-packages (from fairseq2) (4.15.0)\n",
      "Collecting blobfile~=3.0.0 (from fairseq2)\n",
      "  Using cached blobfile-3.0.0-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: torch==2.6.0 in ./.venv/lib/python3.12/site-packages (from fairseq2n==0.4.6->fairseq2) (2.6.0)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.12/site-packages (from torch==2.6.0->fairseq2n==0.4.6->fairseq2) (3.19.1)\n",
      "Requirement already satisfied: networkx in ./.venv/lib/python3.12/site-packages (from torch==2.6.0->fairseq2n==0.4.6->fairseq2) (3.5)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.12/site-packages (from torch==2.6.0->fairseq2n==0.4.6->fairseq2) (3.1.6)\n",
      "Requirement already satisfied: fsspec in ./.venv/lib/python3.12/site-packages (from torch==2.6.0->fairseq2n==0.4.6->fairseq2) (2025.7.0)\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.12/site-packages (from torch==2.6.0->fairseq2n==0.4.6->fairseq2) (80.9.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in ./.venv/lib/python3.12/site-packages (from torch==2.6.0->fairseq2n==0.4.6->fairseq2) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.12/site-packages (from sympy==1.13.1->torch==2.6.0->fairseq2n==0.4.6->fairseq2) (1.3.0)\n",
      "Collecting pycryptodomex>=3.8 (from blobfile~=3.0.0->fairseq2)\n",
      "  Using cached pycryptodomex-3.23.0-cp37-abi3-macosx_10_9_universal2.whl.metadata (3.4 kB)\n",
      "Collecting urllib3<3,>=1.25.3 (from blobfile~=3.0.0->fairseq2)\n",
      "  Using cached urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: lxml>=4.9 in ./.venv/lib/python3.12/site-packages (from blobfile~=3.0.0->fairseq2) (6.0.1)\n",
      "Collecting zipp>=0.5 (from importlib_metadata~=7.0->fairseq2)\n",
      "  Using cached zipp-3.23.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich~=13.7->fairseq2)\n",
      "  Downloading markdown_it_py-4.0.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./.venv/lib/python3.12/site-packages (from rich~=13.7->fairseq2) (2.19.2)\n",
      "Requirement already satisfied: portalocker in ./.venv/lib/python3.12/site-packages (from sacrebleu~=2.4->fairseq2) (3.2.0)\n",
      "Requirement already satisfied: regex in ./.venv/lib/python3.12/site-packages (from sacrebleu~=2.4->fairseq2) (2025.8.29)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in ./.venv/lib/python3.12/site-packages (from sacrebleu~=2.4->fairseq2) (0.9.0)\n",
      "Requirement already satisfied: colorama in ./.venv/lib/python3.12/site-packages (from sacrebleu~=2.4->fairseq2) (0.4.6)\n",
      "Collecting requests>=2.26.0 (from tiktoken~=0.7->fairseq2)\n",
      "  Using cached requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich~=13.7->fairseq2)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests>=2.26.0->tiktoken~=0.7->fairseq2)\n",
      "  Downloading charset_normalizer-3.4.3-cp312-cp312-macosx_10_13_universal2.whl.metadata (36 kB)\n",
      "Collecting idna<4,>=2.5 (from requests>=2.26.0->tiktoken~=0.7->fairseq2)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests>=2.26.0->tiktoken~=0.7->fairseq2)\n",
      "  Using cached certifi-2025.8.3-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.12/site-packages (from jinja2->torch==2.6.0->fairseq2n==0.4.6->fairseq2) (3.0.2)\n",
      "Using cached fairseq2-0.4.6-py3-none-any.whl (514 kB)\n",
      "Using cached blobfile-3.0.0-py3-none-any.whl (75 kB)\n",
      "Using cached editdistance-0.8.1-cp312-cp312-macosx_11_0_arm64.whl (79 kB)\n",
      "Using cached importlib_metadata-7.2.1-py3-none-any.whl (25 kB)\n",
      "Using cached importlib_resources-6.5.2-py3-none-any.whl (37 kB)\n",
      "Using cached mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
      "Using cached numpy-1.26.4-cp312-cp312-macosx_11_0_arm64.whl (13.7 MB)\n",
      "Using cached packaging-24.2-py3-none-any.whl (65 kB)\n",
      "Using cached psutil-5.9.8-cp38-abi3-macosx_11_0_arm64.whl (249 kB)\n",
      "Using cached PyYAML-6.0.2-cp312-cp312-macosx_11_0_arm64.whl (173 kB)\n",
      "Using cached rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "Downloading tiktoken-0.11.0-cp312-cp312-macosx_11_0_arm64.whl (996 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m996.7/996.7 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached torcheval-0.0.7-py3-none-any.whl (179 kB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Downloading markdown_it_py-4.0.0-py3-none-any.whl (87 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Using cached pycryptodomex-3.23.0-cp37-abi3-macosx_10_9_universal2.whl (2.5 MB)\n",
      "Using cached requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Downloading charset_normalizer-3.4.3-cp312-cp312-macosx_10_13_universal2.whl (205 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Using cached certifi-2025.8.3-py3-none-any.whl (161 kB)\n",
      "Using cached zipp-3.23.0-py3-none-any.whl (10 kB)\n",
      "Installing collected packages: zipp, urllib3, tqdm, torcheval, pyyaml, pycryptodomex, psutil, packaging, numpy, mypy-extensions, mdurl, importlib_resources, idna, editdistance, charset_normalizer, certifi, requests, markdown-it-py, importlib_metadata, blobfile, tiktoken, rich, fairseq2\n",
      "\u001b[2K  Attempting uninstall: psutil\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 5/23\u001b[0m [pycryptodomex]\n",
      "\u001b[2K    Found existing installation: psutil 7.0.0━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 5/23\u001b[0m [pycryptodomex]\n",
      "\u001b[2K    Uninstalling psutil-7.0.0:m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 5/23\u001b[0m [pycryptodomex]\n",
      "\u001b[2K      Successfully uninstalled psutil-7.0.0━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 5/23\u001b[0m [pycryptodomex]\n",
      "\u001b[2K  Attempting uninstall: packaging━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 5/23\u001b[0m [pycryptodomex]\n",
      "\u001b[2K    Found existing installation: packaging 25.0━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 5/23\u001b[0m [pycryptodomex]\n",
      "\u001b[2K    Uninstalling packaging-25.0:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 5/23\u001b[0m [pycryptodomex]\n",
      "\u001b[2K      Successfully uninstalled packaging-25.0━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 5/23\u001b[0m [pycryptodomex]\n",
      "\u001b[2K  Attempting uninstall: numpy0m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 5/23\u001b[0m [pycryptodomex]\n",
      "\u001b[2K    Found existing installation: numpy 2.3.2━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 5/23\u001b[0m [pycryptodomex]\n",
      "\u001b[2K    Uninstalling numpy-2.3.2:0m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 5/23\u001b[0m [pycryptodomex]\n",
      "\u001b[2K      Successfully uninstalled numpy-2.3.2━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 8/23\u001b[0m [numpy]mex]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23/23\u001b[0m [fairseq2]/23\u001b[0m [fairseq2]\n",
      "\u001b[1A\u001b[2KSuccessfully installed blobfile-3.0.0 certifi-2025.8.3 charset_normalizer-3.4.3 editdistance-0.8.1 fairseq2-0.4.6 idna-3.10 importlib_metadata-7.2.1 importlib_resources-6.5.2 markdown-it-py-4.0.0 mdurl-0.1.2 mypy-extensions-1.1.0 numpy-1.26.4 packaging-24.2 psutil-5.9.8 pycryptodomex-3.23.0 pyyaml-6.0.2 requests-2.32.5 rich-13.9.4 tiktoken-0.11.0 torcheval-0.0.7 tqdm-4.67.1 urllib3-2.5.0 zipp-3.23.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Try installing fairseq2 with specific compatible versions\n",
    "# First try installing fairseq2n directly (the native component)\n",
    "%pip install fairseq2n\n",
    "\n",
    "# Then try fairseq2\n",
    "%pip install fairseq2\n",
    "\n",
    "# If that fails, try with specific versions\n",
    "# %pip install fairseq2==0.2.1 fairseq2n==0.2.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b2abbc",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6f56c5ee",
   "metadata": {},
   "source": [
    "## Installing SONAR & its Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "984875c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/nihesh/Nihesh/sonar\n",
      "Cloning into 'SONAR'...\n",
      "remote: Enumerating objects: 1273, done.\u001b[K\n",
      "remote: Counting objects: 100% (166/166), done.\u001b[K\n",
      "remote: Compressing objects: 100% (115/115), done.\u001b[K\n",
      "remote: Total 1273 (delta 111), reused 51 (delta 51), pack-reused 1107 (from 1)\u001b[K\n",
      "Receiving objects: 100% (1273/1273), 5.48 MiB | 5.15 MiB/s, done.\n",
      "Resolving deltas: 100% (394/394), done.\n",
      "/Users/nihesh/Nihesh/sonar/SONAR\n",
      "Obtaining file:///Users/nihesh/Nihesh/sonar/SONAR\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Checking if build backend supports build_editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing editable metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: sonar-space\n",
      "  Building editable for sonar-space (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sonar-space: filename=sonar_space-0.4.0-py3-none-any.whl size=13553 sha256=c62dd49b9bc49619e5f007bdd132ec0dcc4e9831b89182911c3058d5d1e57206\n",
      "  Stored in directory: /private/var/folders/68/xfvgc1cj3w74fb3f3s9g1vzh0000gn/T/pip-ephem-wheel-cache-nwe41ax4/wheels/4a/ce/d9/b03de7ac8d7fc1a1d48bb38380d06a2fd4ac230a0d7e2d9983\n",
      "Successfully built sonar-space\n",
      "Installing collected packages: sonar-space\n",
      "Successfully installed sonar-space-0.4.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: numpy in /Users/nihesh/Nihesh/sonar/.venv/lib/python3.12/site-packages (1.26.4)\n",
      "Requirement already satisfied: torch in /Users/nihesh/Nihesh/sonar/.venv/lib/python3.12/site-packages (2.6.0)\n",
      "Requirement already satisfied: torchaudio in /Users/nihesh/Nihesh/sonar/.venv/lib/python3.12/site-packages (2.8.0)\n",
      "Collecting soundfile\n",
      "  Using cached soundfile-0.13.1-py2.py3-none-macosx_11_0_arm64.whl.metadata (16 kB)\n",
      "Requirement already satisfied: tqdm in /Users/nihesh/Nihesh/sonar/.venv/lib/python3.12/site-packages (4.67.1)\n",
      "Requirement already satisfied: typing_extensions in /Users/nihesh/Nihesh/sonar/.venv/lib/python3.12/site-packages (4.15.0)\n",
      "Requirement already satisfied: filelock in /Users/nihesh/Nihesh/sonar/.venv/lib/python3.12/site-packages (from torch) (3.19.1)\n",
      "Requirement already satisfied: networkx in /Users/nihesh/Nihesh/sonar/.venv/lib/python3.12/site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in /Users/nihesh/Nihesh/sonar/.venv/lib/python3.12/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /Users/nihesh/Nihesh/sonar/.venv/lib/python3.12/site-packages (from torch) (2025.7.0)\n",
      "Requirement already satisfied: setuptools in /Users/nihesh/Nihesh/sonar/.venv/lib/python3.12/site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /Users/nihesh/Nihesh/sonar/.venv/lib/python3.12/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/nihesh/Nihesh/sonar/.venv/lib/python3.12/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Collecting torch\n",
      "  Using cached torch-2.8.0-cp312-none-macosx_11_0_arm64.whl.metadata (30 kB)\n",
      "Collecting sympy>=1.13.3 (from torch)\n",
      "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting cffi>=1.0 (from soundfile)\n",
      "  Using cached cffi-1.17.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (1.5 kB)\n",
      "Collecting pycparser (from cffi>=1.0->soundfile)\n",
      "  Using cached pycparser-2.22-py3-none-any.whl.metadata (943 bytes)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/nihesh/Nihesh/sonar/.venv/lib/python3.12/site-packages (from jinja2->torch) (3.0.2)\n",
      "Using cached torch-2.8.0-cp312-none-macosx_11_0_arm64.whl (73.6 MB)\n",
      "Using cached soundfile-0.13.1-py2.py3-none-macosx_11_0_arm64.whl (1.1 MB)\n",
      "Using cached cffi-1.17.1-cp312-cp312-macosx_11_0_arm64.whl (178 kB)\n",
      "Using cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "Using cached pycparser-2.22-py3-none-any.whl (117 kB)\n",
      "Installing collected packages: sympy, pycparser, torch, cffi, soundfile\n",
      "\u001b[2K  Attempting uninstall: sympy\n",
      "\u001b[2K    Found existing installation: sympy 1.13.1\n",
      "\u001b[2K    Uninstalling sympy-1.13.1:\n",
      "\u001b[2K      Successfully uninstalled sympy-1.13.1\n",
      "\u001b[2K  Attempting uninstall: torch━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0/5\u001b[0m [sympy]\n",
      "\u001b[2K    Found existing installation: torch 2.6.0\u001b[0m \u001b[32m0/5\u001b[0m [sympy]\n",
      "\u001b[2K    Uninstalling torch-2.6.0:[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/5\u001b[0m [torch]\n",
      "\u001b[2K      Successfully uninstalled torch-2.6.0━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/5\u001b[0m [torch]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5/5\u001b[0m [soundfile]/5\u001b[0m [cffi]]\n",
      "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "sonar-space 0.4.0 requires sox, which is not installed.\n",
      "fairseq2n 0.4.6 requires torch==2.6.0, but you have torch 2.8.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed cffi-1.17.1 pycparser-2.22 soundfile-0.13.1 sympy-1.14.0 torch-2.8.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting sox\n",
      "  Using cached sox-1.5.0-py3-none-any.whl\n",
      "Requirement already satisfied: numpy>=1.9.0 in /Users/nihesh/Nihesh/sonar/.venv/lib/python3.12/site-packages (from sox) (1.26.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.2 in /Users/nihesh/Nihesh/sonar/.venv/lib/python3.12/site-packages (from sox) (4.15.0)\n",
      "Installing collected packages: sox\n",
      "Successfully installed sox-1.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "sonar-space             0.4.0       /Users/nihesh/Nihesh/sonar/SONAR\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# First, make sure we're in the correct directory\n",
    "import os\n",
    "os.chdir('/Users/nihesh/nihesh/sonar')\n",
    "\n",
    "# Remove any previous failed installation\n",
    "import shutil\n",
    "if os.path.exists('SONAR'):\n",
    "    shutil.rmtree('SONAR')\n",
    "\n",
    "# Clone fresh SONAR repository\n",
    "%cd /Users/nihesh/nihesh/sonar\n",
    "!git clone https://github.com/facebookresearch/SONAR.git\n",
    "\n",
    "# Change to SONAR directory\n",
    "%cd SONAR\n",
    "\n",
    "# Install SONAR without dependencies first to avoid fairseq2 conflict\n",
    "%pip install -e . --no-deps\n",
    "\n",
    "# Install the core dependencies manually (skip fairseq2 for now)\n",
    "%pip install numpy torch torchaudio soundfile tqdm typing_extensions\n",
    "\n",
    "# Try installing sox (might fail on some systems, that's OK)\n",
    "%pip install sox || echo \"Sox installation failed - this is OK for basic functionality\"\n",
    "\n",
    "# Verify installation\n",
    "%pip list | grep sonar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af614d43",
   "metadata": {},
   "source": [
    "## Import SONAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24992e0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rouge-score in ./.venv/lib/python3.12/site-packages (0.1.2)\n",
      "Requirement already satisfied: nltk in ./.venv/lib/python3.12/site-packages (3.9.1)\n",
      "Requirement already satisfied: bert-score in ./.venv/lib/python3.12/site-packages (0.3.13)\n",
      "Requirement already satisfied: absl-py in ./.venv/lib/python3.12/site-packages (from rouge-score) (2.3.1)\n",
      "Requirement already satisfied: numpy in ./.venv/lib/python3.12/site-packages (from rouge-score) (1.26.4)\n",
      "Requirement already satisfied: six>=1.14.0 in ./.venv/lib/python3.12/site-packages (from rouge-score) (1.17.0)\n",
      "Requirement already satisfied: click in ./.venv/lib/python3.12/site-packages (from nltk) (8.2.1)\n",
      "Requirement already satisfied: joblib in ./.venv/lib/python3.12/site-packages (from nltk) (1.5.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in ./.venv/lib/python3.12/site-packages (from nltk) (2025.8.29)\n",
      "Requirement already satisfied: tqdm in ./.venv/lib/python3.12/site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.0.0 in ./.venv/lib/python3.12/site-packages (from bert-score) (2.6.0)\n",
      "Requirement already satisfied: pandas>=1.0.1 in ./.venv/lib/python3.12/site-packages (from bert-score) (2.3.2)\n",
      "Requirement already satisfied: transformers>=3.0.0 in ./.venv/lib/python3.12/site-packages (from bert-score) (4.56.0)\n",
      "Requirement already satisfied: requests in ./.venv/lib/python3.12/site-packages (from bert-score) (2.32.5)\n",
      "Requirement already satisfied: matplotlib in ./.venv/lib/python3.12/site-packages (from bert-score) (3.10.6)\n",
      "Requirement already satisfied: packaging>=20.9 in ./.venv/lib/python3.12/site-packages (from bert-score) (24.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.12/site-packages (from pandas>=1.0.1->bert-score) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.12/site-packages (from pandas>=1.0.1->bert-score) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.12/site-packages (from pandas>=1.0.1->bert-score) (2025.2)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.12/site-packages (from torch>=1.0.0->bert-score) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in ./.venv/lib/python3.12/site-packages (from torch>=1.0.0->bert-score) (4.15.0)\n",
      "Requirement already satisfied: networkx in ./.venv/lib/python3.12/site-packages (from torch>=1.0.0->bert-score) (3.5)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.12/site-packages (from torch>=1.0.0->bert-score) (3.1.6)\n",
      "Requirement already satisfied: fsspec in ./.venv/lib/python3.12/site-packages (from torch>=1.0.0->bert-score) (2025.7.0)\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.12/site-packages (from torch>=1.0.0->bert-score) (80.9.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in ./.venv/lib/python3.12/site-packages (from torch>=1.0.0->bert-score) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.12/site-packages (from sympy==1.13.1->torch>=1.0.0->bert-score) (1.3.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in ./.venv/lib/python3.12/site-packages (from transformers>=3.0.0->bert-score) (0.34.4)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./.venv/lib/python3.12/site-packages (from transformers>=3.0.0->bert-score) (6.0.2)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in ./.venv/lib/python3.12/site-packages (from transformers>=3.0.0->bert-score) (0.22.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in ./.venv/lib/python3.12/site-packages (from transformers>=3.0.0->bert-score) (0.6.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in ./.venv/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers>=3.0.0->bert-score) (1.1.9)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.12/site-packages (from jinja2->torch>=1.0.0->bert-score) (3.0.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.venv/lib/python3.12/site-packages (from matplotlib->bert-score) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.12/site-packages (from matplotlib->bert-score) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.12/site-packages (from matplotlib->bert-score) (4.59.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./.venv/lib/python3.12/site-packages (from matplotlib->bert-score) (1.4.9)\n",
      "Requirement already satisfied: pillow>=8 in ./.venv/lib/python3.12/site-packages (from matplotlib->bert-score) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./.venv/lib/python3.12/site-packages (from matplotlib->bert-score) (3.2.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv/lib/python3.12/site-packages (from requests->bert-score) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.12/site-packages (from requests->bert-score) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.12/site-packages (from requests->bert-score) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.12/site-packages (from requests->bert-score) (2025.8.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/nihesh/nltk_data...\n",
      "[nltk_data] Downloading package punkt to /Users/nihesh/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Install additional dependencies for enhanced evaluation metrics\n",
    "%pip install rouge-score nltk bert-score\n",
    "\n",
    "# Download required NLTK data for METEOR score\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6882096f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ SONAR imported successfully\n",
      "SONAR version: 0.4.0\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torchaudio\n",
    "import zipfile\n",
    "import glob\n",
    "from pathlib import Path\n",
    "from IPython.display import Audio, display\n",
    "\n",
    "# Test SONAR imports\n",
    "try:\n",
    "    import sonar\n",
    "    print(\"✓ SONAR imported successfully\")\n",
    "    \n",
    "    # Test if we can access basic functionality\n",
    "    print(f\"SONAR version: {sonar.__version__ if hasattr(sonar, '__version__') else 'Unknown'}\")\n",
    "    \n",
    "except ImportError as e:\n",
    "    print(f\"❌ Failed to import SONAR: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2325a0b",
   "metadata": {},
   "source": [
    "## For advanced users, to set defaults to GPU or CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3477ce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.backends.mps.is_available() and torch.backends.mps.is_built():\n",
    "    device = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985adf2b",
   "metadata": {},
   "source": [
    "## Sonar Models Downloading and Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9a2959d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "Checking cache directory: /Users/nihesh/.cache/fairseq2\n",
      "No fairseq2 cache found\n",
      "✓ Network configuration updated\n",
      "Attempt 1/2 to initialize SONAR pipeline...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nihesh/Nihesh/sonar/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "100%|██████████| 7.45G/7.45G [07:21<00:00, 18.1MB/s]  \n",
      "\n",
      "100%|██████████| 4.21G/4.21G [04:21<00:00, 17.3MB/s]  \n",
      "\n",
      "100%|██████████| 4.63M/4.63M [00:01<00:00, 3.06MB/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ SONAR pipeline initialized successfully!\n",
      "🔧 Moved model to device: mps:0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import glob\n",
    "import torch\n",
    "import torchaudio\n",
    "import time\n",
    "import urllib.request\n",
    "import ssl\n",
    "from pathlib import Path\n",
    "\n",
    "# Set device\n",
    "if torch.backends.mps.is_available() and torch.backends.mps.is_built():\n",
    "    device = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# ====== Step 1: Check Cache and Configure Network ======\n",
    "def check_cache_and_configure():\n",
    "    \"\"\"Check what's already downloaded and configure network settings\"\"\"\n",
    "    \n",
    "    # Check fairseq2 cache\n",
    "    cache_dir = Path.home() / \".cache\" / \"fairseq2\"\n",
    "    print(f\"Checking cache directory: {cache_dir}\")\n",
    "    \n",
    "    if cache_dir.exists():\n",
    "        print(\"Found fairseq2 cache:\")\n",
    "        for item in cache_dir.rglob(\"*\"):\n",
    "            if \"sonar\" in str(item).lower():\n",
    "                print(f\"  {item}\")\n",
    "    else:\n",
    "        print(\"No fairseq2 cache found\")\n",
    "    \n",
    "    # Create SSL context that's more permissive\n",
    "    ssl_context = ssl.create_default_context()\n",
    "    ssl_context.check_hostname = False\n",
    "    ssl_context.verify_mode = ssl.CERT_NONE\n",
    "    \n",
    "    # Set global SSL context\n",
    "    ssl._create_default_https_context = lambda: ssl_context\n",
    "    \n",
    "    print(\"✓ Network configuration updated\")\n",
    "\n",
    "# ====== Step 2: Initialize SONAR with Enhanced Retry Logic ======\n",
    "def initialize_sonar_enhanced(max_retries=2, delay=2):\n",
    "    \"\"\"Enhanced initialization with better error handling\"\"\"\n",
    "    \n",
    "    check_cache_and_configure()\n",
    "    \n",
    "    last_error = None  # Store the last error for potential re-raising\n",
    "    \n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            print(f\"Attempt {attempt + 1}/{max_retries} to initialize SONAR pipeline...\")\n",
    "            \n",
    "            # Try with increased timeout and better error handling\n",
    "            from sonar.inference_pipelines.speech import SpeechToTextModelPipeline\n",
    "            \n",
    "            s2t_model = SpeechToTextModelPipeline(\n",
    "                encoder=\"sonar_speech_encoder_eng\",\n",
    "                decoder=\"text_sonar_basic_decoder\",\n",
    "                tokenizer=\"text_sonar_basic_decoder\"\n",
    "            ).to(device)\n",
    "            \n",
    "            print(\"✓ SONAR pipeline initialized successfully!\")\n",
    "            return s2t_model\n",
    "            \n",
    "        except Exception as e:\n",
    "            last_error = e  # Store the error for potential re-raising\n",
    "            print(f\"❌ Attempt {attempt + 1} failed: {str(e)[:200]}...\")\n",
    "            \n",
    "            if \"Connection\" in str(e) or \"download\" in str(e).lower():\n",
    "                print(\"  Network issue detected - trying longer delay...\")\n",
    "                delay_time = delay * (attempt + 1)  # Exponential backoff\n",
    "            else:\n",
    "                delay_time = delay\n",
    "                \n",
    "            if attempt < max_retries - 1:\n",
    "                print(f\"  Waiting {delay_time} seconds before retry...\")\n",
    "                time.sleep(delay_time)\n",
    "            else:\n",
    "                print(\"All attempts failed. Trying alternative approach...\")\n",
    "                break\n",
    "    \n",
    "    # If all retries failed, try a different model configuration\n",
    "    print(\"\\n====== Trying Alternative Model Configuration ======\")\n",
    "    try:\n",
    "        # Try with just the basic text model first\n",
    "        from sonar.inference_pipelines.text import TextToTextModelPipeline\n",
    "        print(\"Trying text-only pipeline first...\")\n",
    "        \n",
    "        text_model = TextToTextModelPipeline(\n",
    "            encoder=\"text_sonar_basic_encoder\",\n",
    "            decoder=\"text_sonar_basic_decoder\",\n",
    "            tokenizer=\"text_sonar_basic_encoder\"\n",
    "        )\n",
    "        \n",
    "        print(\"✓ Text pipeline works - network issue is specific to speech models\")\n",
    "        print(\"You may need to download the speech model manually or try a VPN\")\n",
    "        return None\n",
    "        \n",
    "    except Exception as e2:\n",
    "        print(f\"❌ Even text pipeline failed: {e2}\")\n",
    "        print(\"\\nTroubleshooting suggestions:\")\n",
    "        print(\"1. Check your internet connection\")\n",
    "        print(\"2. Try using a VPN to change your IP location\")\n",
    "        print(\"3. Check if your firewall/antivirus is blocking downloads\")\n",
    "        print(\"4. Try running this on a different network\")\n",
    "        raise last_error if last_error else e2\n",
    "\n",
    "# Run the enhanced initialization\n",
    "s2t_model = initialize_sonar_enhanced()\n",
    "if s2t_model:\n",
    "    s2t_model.to(device)\n",
    "    print(f\"🔧 Moved model to device: {next(s2t_model.parameters()).device}\")\n",
    "else:\n",
    "    print(\"Model initialization failed, proceeding without model for now\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd13fb51",
   "metadata": {},
   "source": [
    "## Sonar Running and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3dfd6dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Loading progress…\n",
      "📂 Found progress.json — 2936 files already done\n",
      "🔍 Loading cache…\n",
      "🗄️  Loaded 2936 cached results\n",
      "📊 Total .wav files: 2936\n",
      "✅ Already processed: 2936\n",
      "⏳ Remaining: 0\n",
      "✅ Done processing current batch\n",
      "🎉 All files processed! Running evaluation…\n",
      "🔹 BLEU score: 1.00\n",
      "🔹 ChrF++ score: 10.88\n",
      "🔹 BLEU score: 1.00\n",
      "🔹 ChrF++ score: 10.88\n",
      "🔹 TER score: 103.03\n",
      "🔹 TER score: 103.03\n",
      "🔹 ROUGE-1 F1: 0.1036\n",
      "🔹 ROUGE-2 F1: 0.0243\n",
      "🔹 ROUGE-L F1: 0.0950\n",
      "🔹 ROUGE-1 F1: 0.1036\n",
      "🔹 ROUGE-2 F1: 0.0243\n",
      "🔹 ROUGE-L F1: 0.0950\n",
      "🔹 METEOR score: 0.0467\n",
      "🔹 METEOR score: 0.0467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔹 BERTScore Precision: 0.8381\n",
      "🔹 BERTScore Recall: 0.8332\n",
      "🔹 BERTScore F1: 0.8352\n",
      "🔹 BERTScore Recall: 0.8332\n",
      "🔹 BERTScore F1: 0.8352\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import os\n",
    "import datetime\n",
    "import torch\n",
    "import torchaudio\n",
    "import sacrebleu\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available()\n",
    "                      else (\"mps\" if torch.backends.mps.is_available() else \"cpu\"))\n",
    "\n",
    "def translate_speech_to_text_optimized(audio_path, target_lang=\"eng\"):\n",
    "    try:\n",
    "        waveform, sr = torchaudio.load(audio_path)\n",
    "        waveform = waveform.to(device)\n",
    "        print(f\"Device type:      {device.type}\")\n",
    "        print(f\"Waveform device:  {waveform.device}\")\n",
    "        if s2t_model:\n",
    "            print(f\"Model device:     {next(s2t_model.parameters()).device}\")\n",
    "        else:\n",
    "            print(\"Model not available\")\n",
    "\n",
    "        if sr != 16000:\n",
    "            waveform = torchaudio.transforms.Resample(sr, 16000).to(device)(waveform)\n",
    "        if waveform.size(0) > 1:\n",
    "            waveform = waveform.mean(dim=0, keepdim=True)\n",
    "        if device.type in (\"cuda\", \"mps\") and s2t_model:\n",
    "            with torch.amp.autocast(device_type=device.type, enabled=True):\n",
    "                out = s2t_model.predict([waveform], f\"{target_lang}_Latn\", max_seq_len=256)\n",
    "        elif s2t_model:\n",
    "            out = s2t_model.predict([waveform], f\"{target_lang}_Latn\", max_seq_len=256)\n",
    "        else:\n",
    "            return \"ERROR: Model not initialized\"\n",
    "\n",
    "        return out[0] if out else \"ERROR: No output\"\n",
    "    except Exception as e:\n",
    "        return f\"ERROR: {e}\"\n",
    "\n",
    "\n",
    "cwd = Path.cwd()\n",
    "test_folder = cwd / \"test\"\n",
    "audio_folder = test_folder / \"audio\"\n",
    "cache_dir = cwd / \".sonar_cache\"\n",
    "cache_dir.mkdir(exist_ok=True)\n",
    "progress_file = cache_dir / \"progress.json\"\n",
    "results_cache = cache_dir / \"results.pkl\"\n",
    "output_file = cwd / \"sonar_translated_output.txt\"\n",
    "transcript_file = test_folder / \"transcript.txt\"\n",
    "tgt_lang = \"eng\"\n",
    "\n",
    "print(\"🔍 Loading progress…\")\n",
    "try:\n",
    "    with open(progress_file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    processed_files = set(data.get('processed_files', []))\n",
    "    print(f\"📂 Found progress.json — {len(processed_files)} files already done\")\n",
    "except (FileNotFoundError, json.JSONDecodeError):\n",
    "    processed_files = set()\n",
    "    print(\"📂 No valid progress.json found; starting fresh\")\n",
    "\n",
    "print(\"🔍 Loading cache…\")\n",
    "try:\n",
    "    with open(results_cache, 'rb') as f:\n",
    "        cached_results = pickle.load(f)\n",
    "    processed_files.update(cached_results.keys())\n",
    "    print(f\"🗄️  Loaded {len(cached_results)} cached results\")\n",
    "except (FileNotFoundError, EOFError):\n",
    "    cached_results = {}\n",
    "    print(\"🗄️  No cache file found; starting with empty results\")\n",
    "\n",
    "if not audio_folder.exists():\n",
    "    new_path = input(f\"❌ Audio folder not found at {audio_folder}. Enter test folder path: \")\n",
    "    test_folder = Path(new_path)\n",
    "    audio_folder = test_folder / \"audio\"\n",
    "    transcript_file = test_folder / \"transcript.txt\"\n",
    "\n",
    "audio_files = sorted(audio_folder.glob(\"*.wav\"))\n",
    "total = len(audio_files)\n",
    "remaining = [p for p in audio_files if p.name not in processed_files]\n",
    "print(f\"📊 Total .wav files: {total}\")\n",
    "print(f\"✅ Already processed: {total - len(remaining)}\")\n",
    "print(f\"⏳ Remaining: {len(remaining)}\")\n",
    "\n",
    "with open(output_file, \"a\", encoding=\"utf-8\") as out_f:\n",
    "    try:\n",
    "        for i, path in enumerate(remaining, 1):\n",
    "            name = path.name\n",
    "            print(f\"🔄 Processing {i}/{len(remaining)}: {name}\")\n",
    "            text = translate_speech_to_text_optimized(path, target_lang=tgt_lang)\n",
    "            cached_results[name] = text\n",
    "            processed_files.add(name)\n",
    "            out_f.write(f\"{name}\\t{text}\\n\")\n",
    "            out_f.flush()\n",
    "\n",
    "            if i % 5 == 0 or i == len(remaining):\n",
    "                print(f\"💾 Saving progress at file {i}…\")\n",
    "                with open(progress_file, 'w') as pf:\n",
    "                    json.dump({\n",
    "                        'processed_files': list(processed_files),\n",
    "                        'last_updated': datetime.datetime.now().isoformat()\n",
    "                    }, pf, indent=2)\n",
    "                with open(results_cache, 'wb') as rf:\n",
    "                    pickle.dump(cached_results, rf)\n",
    "\n",
    "        print(\"✅ Done processing current batch\")\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n⏸️  Interrupted by user — saving progress…\")\n",
    "        with open(progress_file, 'w') as pf:\n",
    "            json.dump({\n",
    "                'processed_files': list(processed_files),\n",
    "                'last_updated': datetime.datetime.now().isoformat(),\n",
    "                'interrupted': True\n",
    "            }, pf, indent=2)\n",
    "        with open(results_cache, 'wb') as rf:\n",
    "            pickle.dump(cached_results, rf)\n",
    "        print(f\"💾 Final save complete: {len(processed_files)}/{total} files\")\n",
    "        # Exit the cell here; do not run evaluation\n",
    "        raise\n",
    "\n",
    "# Only run evaluation if we processed everything:\n",
    "if len(processed_files) == total:\n",
    "    print(\"🎉 All files processed! Running evaluation…\")\n",
    "    if transcript_file.exists():\n",
    "        ref = {}\n",
    "        with open(transcript_file, 'r', encoding='utf-8') as rf:\n",
    "            for line in rf:\n",
    "                k, v = line.strip().split('|', 1)\n",
    "                ref[k.lower()] = v\n",
    "        hyps, refs = [], []\n",
    "        for fn, hyp in cached_results.items():\n",
    "            if fn.lower() in ref and not hyp.startswith(\"ERROR:\"):\n",
    "                hyps.append(hyp)\n",
    "                refs.append(ref[fn.lower()])\n",
    "        if hyps:\n",
    "            bleu = sacrebleu.corpus_bleu(hyps, [refs])\n",
    "            chrf = sacrebleu.corpus_chrf(hyps, [refs])\n",
    "            ter = sacrebleu.corpus_ter(hyps, [refs])\n",
    "            print(f\"🔹 BLEU score: {bleu.score:.2f}\", flush=True)\n",
    "            print(f\"🔹 ChrF++ score: {chrf.score:.2f}\", flush=True)\n",
    "            print(f\"🔹 TER score: {ter.score:.2f}\", flush=True)\n",
    "            \n",
    "            # ROUGE\n",
    "            from rouge_score import rouge_scorer\n",
    "            scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "            rouge_scores = [scorer.score(ref, hyp) for ref, hyp in zip(refs, hyps)]\n",
    "            avg_rouge1 = sum(s['rouge1'].fmeasure for s in rouge_scores) / len(rouge_scores)\n",
    "            avg_rouge2 = sum(s['rouge2'].fmeasure for s in rouge_scores) / len(rouge_scores)\n",
    "            avg_rougeL = sum(s['rougeL'].fmeasure for s in rouge_scores) / len(rouge_scores)\n",
    "            print(f\"🔹 ROUGE-1 F1: {avg_rouge1:.4f}\", flush=True)\n",
    "            print(f\"🔹 ROUGE-2 F1: {avg_rouge2:.4f}\", flush=True)\n",
    "            print(f\"🔹 ROUGE-L F1: {avg_rougeL:.4f}\", flush=True)\n",
    "            \n",
    "            # METEOR\n",
    "            from nltk.translate.meteor_score import meteor_score\n",
    "            meteor_scores = [meteor_score([ref.split()], hyp.split()) for ref, hyp in zip(refs, hyps)]\n",
    "            avg_meteor = sum(meteor_scores) / len(meteor_scores)\n",
    "            print(f\"🔹 METEOR score: {avg_meteor:.4f}\", flush=True)\n",
    "            \n",
    "            # BERTScore\n",
    "            from bert_score import score\n",
    "            P, R, F1 = score(hyps, refs, lang='en', verbose=False)\n",
    "            print(f\"🔹 BERTScore Precision: {P.mean():.4f}\", flush=True)\n",
    "            print(f\"🔹 BERTScore Recall: {R.mean():.4f}\", flush=True)\n",
    "            print(f\"🔹 BERTScore F1: {F1.mean():.4f}\", flush=True)\n",
    "            \n",
    "            with open(cache_dir / \"evaluation_results.json\", 'w') as ef:\n",
    "                json.dump({\n",
    "                    'bleu_score': bleu.score,\n",
    "                    'chrf_score': chrf.score,\n",
    "                    'ter_score': ter.score,\n",
    "                    'rouge1_f1': avg_rouge1,\n",
    "                    'rouge2_f1': avg_rouge2,\n",
    "                    'rougeL_f1': avg_rougeL,\n",
    "                    'meteor_score': avg_meteor,\n",
    "                    'bert_precision': P.mean().item(),\n",
    "                    'bert_recall': R.mean().item(),\n",
    "                    'bert_f1': F1.mean().item(),\n",
    "                    'matched_files': len(hyps),\n",
    "                    'total_files': total,\n",
    "                    'timestamp': datetime.datetime.now().isoformat()\n",
    "                }, ef, indent=2)\n",
    "        else:\n",
    "            print(\"⚠️  No matching transcripts for evaluation.\")\n",
    "    else:\n",
    "        print(f\"❌ transcript.txt not found at {transcript_file}; skipping evaluation.\")\n",
    "else:\n",
    "    print(f\"⌛ {len(processed_files)}/{total} done. Run again to resume.\")\n",
    "\n",
    "\n",
    "\n",
    "# Clear cache command (uncomment to reset)\n",
    "# import shutil\n",
    "# shutil.rmtree(cache_dir)\n",
    "# print(\"🗑️  Cache cleared\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3705a8e",
   "metadata": {},
   "source": [
    "### Checking if GPU or CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9efd177-14c8-41e8-aecd-166f1065ff4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.backends.mps.is_available() and torch.backends.mps.is_built():\n",
    "    device = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae4718d",
   "metadata": {},
   "source": [
    "### Checking the files for errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "821c5aa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.3.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (91 kB)\n",
      "  Downloading pandas-2.3.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (91 kB)\n",
      "Requirement already satisfied: numpy>=1.26.0 in ./.venv/lib/python3.12/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Using cached pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Requirement already satisfied: numpy>=1.26.0 in ./.venv/lib/python3.12/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Using cached pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Using cached tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Downloading pandas-2.3.1-cp312-cp312-macosx_11_0_arm64.whl (10.7 MB)\n",
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/10.7 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0mCollecting tzdata>=2022.7 (from pandas)\n",
      "  Using cached tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Downloading pandas-2.3.1-cp312-cp312-macosx_11_0_arm64.whl (10.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.7/10.7 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Using cached tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.7/10.7 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Using cached tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Installing collected packages: pytz, tzdata, pandas\n",
      "\u001b[?25lInstalling collected packages: pytz, tzdata, pandas\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/3\u001b[0m [pandas]2m2/3\u001b[0m [pandas]\n",
      "\u001b[1A\u001b[2KSuccessfully installed pandas-2.3.1 pytz-2025.2 tzdata-2025.2\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/3\u001b[0m [pandas]\n",
      "\u001b[1A\u001b[2KSuccessfully installed pandas-2.3.1 pytz-2025.2 tzdata-2025.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "97631ba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking transcript file: /Users/nihesh/Nihesh/sonar/test/transcript.txt\n",
      "Checking output file: /Users/nihesh/Nihesh/sonar/sonar_translated_output.txt\n",
      "\n",
      "🔍 Analyzing transcript.txt format...\n",
      "Detected separator in transcript file: '|'\n",
      "Read 2936 entries from transcript.txt\n",
      "\n",
      "🔍 Analyzing sonar_translated_output.txt format...\n",
      "Detected separator in output file: '\\t'\n",
      "Read 2936 entries from sonar_translated_output.txt\n",
      "\n",
      "✅ No duplicates found in output file\n",
      "\n",
      "📊 Comparison Summary:\n",
      "Transcript entries: 2936\n",
      "Output entries: 2936\n",
      "Entries in both files: 2936\n",
      "Entries only in transcript: 0\n",
      "Entries only in output: 0\n",
      "\n",
      "📝 Sample transcript entries:\n",
      "  iiith_tdbc_yt_set16_96_96_0018.wav: Right from my childhood I am an actor.At the time of shool I had acted on the stage located in the school.\n",
      "  iiith_dbc_pe_tel_ca_1021_51054.wav: Talking about the Ahobilam Temple in Anantapur — one word isn’t enough. So many people keep visiting because the temple is so beautiful that two eyes aren’t enough to take it all in\n",
      "  iiith_dbc_pe_tel_ca_1023_36710.wav: My father was a farmer and he had a lot of respect for his profession and he worked hard honestly and did not expect anything from anyone.\n",
      "\n",
      "📝 Sample output entries:\n",
      "  000abe8232c34471a6bddcfa78665506.wav: I'm helping you. I'm helping you. I'm helping you.\n",
      "  004f2c6a7f7245acb9413d4a42515cd1.wav: I want to see you. I want to see you.\n",
      "  00649e6e98c8432fa02b8f81b960eabf.wav: I do want to know. I do want to know.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def check_files():\n",
    "    cwd = Path.cwd()\n",
    "    test_folder = cwd / \"test\"\n",
    "    transcript_file = test_folder / \"transcript.txt\"\n",
    "    output_file = cwd / \"sonar_translated_output.txt\"\n",
    "    \n",
    "    # Check if files exist\n",
    "    print(f\"Checking transcript file: {transcript_file}\")\n",
    "    if not transcript_file.exists():\n",
    "        print(f\"❌ Transcript file not found at {transcript_file}\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Checking output file: {output_file}\")\n",
    "    if not output_file.exists():\n",
    "        print(f\"❌ Output file not found at {output_file}\")\n",
    "        return\n",
    "    \n",
    "    # Read transcript file\n",
    "    transcript_data = {}\n",
    "    transcript_separator = None\n",
    "    print(\"\\n🔍 Analyzing transcript.txt format...\")\n",
    "    \n",
    "    with open(transcript_file, 'r', encoding='utf-8') as f:\n",
    "        sample_lines = [next(f) for _ in range(min(5, sum(1 for _ in open(transcript_file))))]\n",
    "    \n",
    "    # Detect separator in transcript file\n",
    "    for line in sample_lines:\n",
    "        if '|' in line:\n",
    "            transcript_separator = '|'\n",
    "            break\n",
    "        elif '\\t' in line:\n",
    "            transcript_separator = '\\t'\n",
    "            break\n",
    "    \n",
    "    print(f\"Detected separator in transcript file: {repr(transcript_separator)}\")\n",
    "    \n",
    "    # Read transcript file with correct separator\n",
    "    with open(transcript_file, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            try:\n",
    "                if transcript_separator:\n",
    "                    k, v = line.strip().split(transcript_separator, 1)\n",
    "                    transcript_data[k.lower()] = v\n",
    "                else:\n",
    "                    print(f\"⚠️ Could not parse line: {line.strip()}\")\n",
    "            except ValueError:\n",
    "                print(f\"⚠️ Error parsing line: {line.strip()}\")\n",
    "    \n",
    "    print(f\"Read {len(transcript_data)} entries from transcript.txt\")\n",
    "    \n",
    "    # Read output file\n",
    "    output_data = {}\n",
    "    output_separator = None\n",
    "    output_keys = []\n",
    "    print(\"\\n🔍 Analyzing sonar_translated_output.txt format...\")\n",
    "    \n",
    "    with open(output_file, 'r', encoding='utf-8') as f:\n",
    "        sample_lines = [next(f) for _ in range(min(5, sum(1 for _ in open(output_file))))]\n",
    "    \n",
    "    # Detect separator in output file\n",
    "    for line in sample_lines:\n",
    "        if '\\t' in line:\n",
    "            output_separator = '\\t'\n",
    "            break\n",
    "        elif ' ' in line and not line.startswith(' '):\n",
    "            output_separator = ' '\n",
    "            break\n",
    "    \n",
    "    print(f\"Detected separator in output file: {repr(output_separator)}\")\n",
    "    \n",
    "    # Read output file with correct separator\n",
    "    with open(output_file, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            try:\n",
    "                if output_separator:\n",
    "                    k, v = line.strip().split(output_separator, 1)\n",
    "                    output_data[k.lower()] = v\n",
    "                    output_keys.append(k.lower())\n",
    "                else:\n",
    "                    print(f\"⚠️ Could not parse line: {line.strip()}\")\n",
    "            except ValueError:\n",
    "                print(f\"⚠️ Error parsing line: {line.strip()}\")\n",
    "    \n",
    "    print(f\"Read {len(output_data)} entries from sonar_translated_output.txt\")\n",
    "    \n",
    "    # Check for duplicates in output file\n",
    "    duplicates = [x for x in output_keys if output_keys.count(x) > 1]\n",
    "    unique_duplicates = set(duplicates)\n",
    "    \n",
    "    if unique_duplicates:\n",
    "        print(f\"\\n⚠️ Found {len(unique_duplicates)} duplicate keys in output file:\")\n",
    "        for dup in unique_duplicates:\n",
    "            print(f\"  - {dup} appears {output_keys.count(dup)} times\")\n",
    "    else:\n",
    "        print(\"\\n✅ No duplicates found in output file\")\n",
    "    \n",
    "    # Compare files\n",
    "    trans_keys = set(transcript_data.keys())\n",
    "    out_keys = set(output_data.keys())\n",
    "    \n",
    "    print(\"\\n📊 Comparison Summary:\")\n",
    "    print(f\"Transcript entries: {len(trans_keys)}\")\n",
    "    print(f\"Output entries: {len(out_keys)}\")\n",
    "    print(f\"Entries in both files: {len(trans_keys & out_keys)}\")\n",
    "    print(f\"Entries only in transcript: {len(trans_keys - out_keys)}\")\n",
    "    print(f\"Entries only in output: {len(out_keys - trans_keys)}\")\n",
    "    \n",
    "    # Print sample entries\n",
    "    print(\"\\n📝 Sample transcript entries:\")\n",
    "    for k in list(transcript_data.keys())[:3]:\n",
    "        print(f\"  {k}: {transcript_data[k]}\")\n",
    "    \n",
    "    print(\"\\n📝 Sample output entries:\")\n",
    "    for k in list(output_data.keys())[:3]:\n",
    "        print(f\"  {k}: {output_data[k]}\")\n",
    "\n",
    "# Run the check\n",
    "check_files()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
